# dbt_practice
1. создаем проект в pycharm
2. создаем `python -m venv .venv` или автоматически
3. активируем окружение `source .venv/bin/activate`
4. грузим библиотеки `pip install dbt`
5. проверяем версию `dbt --version`
6. инициализируем проект `dbt init [имя проекта]` создастся одноименная папка 
с костяком ососбое внимание к файлу __dbt-project.yml__
7. создем __docker-compose.yml__
там пропишем:
- версию postgres
- логин пароль с postgres
- путь к папке с __РАСПАКОВАННЫМ__ бэкапом.zip или .tar с базой postgres типа **- ./dvdrental:/dvdrental**
- путь к папке с базой типа **- .db/:/var/lib/postgresql/data**
- прописываем порты типа **[любой]:5432**
- комментируем в файле __build и context__
- `docker-compose up --build`
- должен запуститься контейнер
8. переходим в контейнер `docker exec -it [id container] bash`
9. там восстанавливаем базу `pg_restore -U postgres -d dvdrental /dvdrental`
где:
- -U это пользователь
- -d это имя базы
- /папка с разархивированным бэкапом
10. либо эта база будет исходной сырой базой, которую будем транформировать в витрины
11. создаем профиль в корневой папке компа __.dbt__ файл __profile.yml__
12. название профиля должно совпадать с названием проекта и названием __profile: 'имя проекта=профиля'__ в файле __dbt-project.yml__ из пункта 6.
13. транформации=модели=задачки находятся в папке __models__ в которой есть подпапки 
14. в папке с моделями создаем файл и описанием источника __sourcr.yml__
15. перед запуском помпилируем модели `dbt compile`
16. модели запускаются `dbt run`. Если профиль прописан нормально, то запустятся абсолютно все
17. запустить конкрктную модель `dbt run -m [имя модели без .sql]`
18. чтобы результирующие сущности материализовывались в таблицы или вьюхи проиписываем это
в файле __dbt-project.yml__ в разделе __models:__ либо в самом файле с моделью
типа __{{ config(materialized='table') }}__
19. снапшоты задаем в папке __snapshots__ как __файлы.sql__
20. там прописываем целевую схему со снапшотами столбуц с ключом и и временной меткой
21. Запускаем командой `dbt snapshot`
22. в результате в снапшотной схеме появится таблица похожая на исходную со спец полями по стандарту SCD2
23. использует добавление новой строки и дополнительных столбцов. Такой подход позволяет сохранить историчность.
24. для запуска вебинтерфрейса `dbt docs generate` для создания документа с документацией
без него не будет работать
25. потом `dbt docs serve --port 8001` обычно порт занят под airflow
так что принудительно задаем иной порт
26. как писал ранее все преобразования прописаны в sql файлах в моделях
27. лучше все делать по принципу __ELT__ т.е. простыми селектами переносить из
исходной схемы в стэйджинговую нужные таблицы а потом дугими моделями делать 
более слежные штуки с джойнами и проч хуйней через конструкции типа 
`select *, from {{ref("tab1")}} t1 join {{ref("tab2")}} t2 on t1.id = t2.id`
28. эти цепочки отделных задачак будут видны в ДАГах в UI
29. тэги задаются в файле __dbt-project.yml__ в разделе с моделями
30. удобно будет запускать `dbt run -m tag:[имя тэга]` чтоб не хуярить все подряд
31. тесты пишем как запросы в sql файлах в папке tests. Если тест что-то вернул значит он провалился
т.е. если нам нужно отловить пропуск мы пишем `select * from {{ref ("таблица")}} where поле is null`
если пропуск в этой таблице этом поле есть вернется что-то значит тест провалился
так можно записывать любую хуйню. типа:
- дата конца меньше чем дата начала, 
- сумма > какого-то порога
- количество < 0
- и т.д.
32. 